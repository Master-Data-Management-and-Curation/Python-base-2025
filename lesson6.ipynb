{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 6: Advanced PyTorch: DataLoaders and Pre-trained Models\n",
    "\n",
    "**Objective:** To learn the standard workflow for handling datasets and leverage the power of pre-trained models for advanced tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Problem with Manual Batching\n",
    "In our last session, we fed the entire dataset to the model at once. This is not feasible for large datasets that don't fit in memory. The solution is to process data in small batches. PyTorch provides elegant tools for this: `Dataset` and `DataLoader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `Dataset` and `DataLoader`\n",
    "- **`torch.utils.data.Dataset`:** An abstract class that represents a dataset. You typically create a custom class that inherits from it and implements two key methods:\n",
    "    - `__len__(self)`: Returns the total number of samples in the dataset.\n",
    "    - `__getitem__(self, idx)`: Returns the sample (e.g., an image and its label) at a given index `idx`.\n",
    "- **`torch.utils.data.DataLoader`:** A data loader that wraps a `Dataset` and provides an iterable over it. It handles batching, shuffling, and even parallel data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does \"Inherit\" mean?\n",
    "# Parent class\n",
    "class Animal:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def eat(self):\n",
    "        return f\"{self.name} is eating.\"\n",
    "\n",
    "# Child class inherits from Animal\n",
    "class Dog(Animal):\n",
    "    def bark(self):\n",
    "        return f\"{self.name} says Woof!\"\n",
    "\n",
    "# Create an object of the Dog class\n",
    "my_dog = Dog(\"Rex\")\n",
    "\n",
    "# Call method from the parent class (Animal)\n",
    "print(my_dog.eat())  # Output: Rex is eating.\n",
    "\n",
    "# Call method from the child class (Dog)\n",
    "print(my_dog.bark()) # Output: Rex says Woof!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is typically inherited by the Dataset class?\n",
    "\n",
    "For one thing, the Dataset class is expected to have some methods which are indeed `__len__` and `__getitem__`. Secondly, there are utility functions such as `__add__` which concatenates different datasets and similar methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Create a simple custom dataset\n",
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Sample data\n",
    "X = torch.randn(100, 10) # 100 samples, 10 features each\n",
    "y = torch.randint(0, 2, (100,)) # 100 labels (0 or 1)\n",
    "\n",
    "# Instantiate the dataset and dataloader\n",
    "dataset = MyCustomDataset(X, y)\n",
    "\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Iterate over the data\n",
    "first_batch_features, first_batch_labels = next(iter(data_loader))\n",
    "print(f\"Feature batch shape: {first_batch_features.shape}\") \n",
    "print(f\"Label batch shape: {first_batch_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GPU Acceleration with `.to(device)`\n",
    "To speed up training, you can move your model and data to a GPU (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check for GPU and set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# 2. Move your model to the device (example)\n",
    "# model = YourModelClass()\n",
    "# model.to(device)\n",
    "\n",
    "# 3. Inside your training loop, you would move each batch of data to the device\n",
    "# for features, labels in data_loader:\n",
    "#     features = features.to(device)\n",
    "#     labels = labels.to(device)\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Loading Pre-trained Models (Transfer Learning)\n",
    "Why train a huge model from scratch when you can use one trained by experts on massive datasets? This is called **transfer learning**. `torchvision.models` provides many famous, pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Load a pre-trained ResNet-18 model\n",
    "# pretrained=True downloads the weights trained on the ImageNet dataset\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "resnet18.eval()\n",
    "\n",
    "# print(resnet18) # You can inspect all the layers!\n",
    "\n",
    "# To use it, you need to provide an input tensor with the correct shape\n",
    "# and apply the same transformations the model was trained on.\n",
    "# For now, let's create a dummy image tensor.\n",
    "# (Batch size, Channels, Height, Width)\n",
    "dummy_image = torch.randn(1, 3, 224, 224)\n",
    "output = resnet18(dummy_image)\n",
    "\n",
    "# The output is a tensor of shape [1, 1000] because ImageNet has 1000 classes.\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exercises & Debugging (90 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 6.1: Load and Inspect a Pre-trained Model\n",
    "* **Task:** Load the pre-trained `alexnet` model from `torchvision.models`. Print the model architecture to the screen. Create a dummy input tensor of the correct size for a single image and pass it through the model to get the output.\n",
    "* **Hint:** AlexNet, like ResNet, expects a 224x224 RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load pre-trained AlexNet\n",
    "\n",
    "# Print the model\n",
    "\n",
    "# Create a dummy input tensor (1 image, 3 channels, 224x224)\n",
    "\n",
    "# Get the output\n",
    "\n",
    "# The output has 1000 classes for ImageNet\n",
    "print(f\"\\nOutput shape: {output.shape}\")\n",
    "print(f\"Predicted class index: {torch.argmax(output, 1).item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
